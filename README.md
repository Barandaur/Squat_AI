# Squat.AI

## Our Team
This work couldn't have been possible without an amazing team, so acknowledgements go to: 
- Alessandro Pisano ([Linkedin](https://www.linkedin.com/in/alessandro-pisano-276048161/), [GitHub](https://github.com/alessandro-pisano)), 
- Caterina Fabbri ([Linkedin](https://www.linkedin.com/in/caterina-fabbri/), [GitHub](https://github.com/CaterinaFabbri)), 
- Chiara di Bonaventura ([Linkedin](https://www.linkedin.com/in/chiara-di-bonaventura/), [GitHub]()), 
- Flavia Monaci ([Linkedin](https://www.linkedin.com/in/flavia-monaci-76503319a/), [GitHub]())

## Project Description
As coursework for the Computer Vision exam, my team produced a script which takes videos of a squatting person as input, and returns whether the exercise is correctly done or, otherwise, feedback on the mistake.

We used a similar approach to Ogata et al. (2019). Notably, our main strategy was to carry out a multi-class classification task based on temporal distance matrices computed on the 2D body joints retrieved from the videos.
